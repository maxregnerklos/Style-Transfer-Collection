# Import necessary libraries
import os
import cv2
import imageio
import numpy as np
from PIL import Image
from google.colab import files
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import clear_output, HTML, Image as ipythonimage
import moviepy.editor as mpy
from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter
from IPython import display as ipythondisplay

# Set up Colab environment
%matplotlib inline
!git clone https://github.com/naoto0804/pytorch-AdaIN.git
%cd /content/pytorch-AdaIN
!mkdir models
%cd /content/pytorch-AdaIN/models
!gdown https://drive.google.com/uc?id=1bMfhMMwPeXnYSQI6cDWElSZxOxc6aVyr
!gdown https://drive.google.com/uc?id=1EpkBA2K2eYILDSyPTt0fztz59UjAIpZU
%cd /content/pytorch-AdaIN

# Function to upload a video
def upload_video():
    # Create 'video' directory
    !rm -rf video
    !mkdir video
    
    # Upload a video file
    uploaded = list(files.upload().keys())
    
    if len(uploaded) != 1:
        raise ValueError('You can only upload one video at a time!')
    
    # Rename the uploaded video file and move it to 'video' directory
    vid = uploaded[0]
    os.rename(vid, vid.replace(" ", ""))
    vid = vid.replace(" ", "")
    !mv -f $vid video/driving.mp4
    vid = '/content/pytorch-AdaIN/video/driving.mp4'
    
    # Get video properties
    fps_of_video = int(cv2.VideoCapture(vid).get(cv2.CAP_PROP_FPS))
    frames_of_video = int(cv2.VideoCapture(vid).get(cv2.CAP_PROP_FRAME_COUNT))
    
    return vid, fps_of_video, frames_of_video

# Function to split video into frames
def split_video_into_frames(vid):
    # Create 'frames' directory
    !rm -rf frames
    !mkdir frames
    
    # Open the video file
    vidcap = cv2.VideoCapture(vid)
    success, image = vidcap.read()
    count = 0
    success = True
    
    while success:
        cv2.imwrite("frames/frame%09d.jpg" % count, image)
        success, image = vidcap.read()
        count += 1
    
    # Display the first frame
    fram = os.listdir("/content/pytorch-AdaIN/frames")
    fram.sort()
    fram_path = '/content/pytorch-AdaIN/frames/' + fram[0]
    print("First frame:\n")
    display(Image.open(fram_path).resize((300, 300)))

# Function to upload a style image
def upload_style_image():
    # Upload a style image
    uploaded = files.upload()
    
    for fn in uploaded.keys():
        print('User uploaded file "{name}" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))
    
    os.rename(fn, fn.replace(" ", ""))
    fn = fn.replace(" ", "")
    pic_name = "photo." + fn.split(".")[-1]
    !mv -f $fn $pic_name
    
    # Display the style image
    display(Image.open(pic_name).resize((300, 300)))
    
    return pic_name

# Function for style transfer
def style_transfer(fram_path, pic_name):
    # Create 'stylized_frames' directory
    !rm -rf stylized_frames
    !mkdir stylized_frames
    
    # Get sizes for content and style images
    im = Image.open(fram_path)
    (width, height) = im.size
    min_size_cont = min(width, height)
    
    im = Image.open(pic_name)
    (width, height) = im.size
    min_size_styl = min(width, height)
    
    temp_path = '/content/pytorch-AdaIN/frames'
    output_path = '/content/pytorch-AdaIN/stylized_frames'
    
    # Perform style transfer
    !CUDA_VISIBLE_DEVICES=0 python test.py --content_dir $temp_path --style $pic_name --output $output_path --content_size $min_size_cont --style_size $min_size_styl

# Function to join frames into a video
def join_frames_into_video(fps_of_video):
    # Create an audio file from the original video
    !ffmpeg -y -i $vid -vn -ar 44100 -ac 2 -ab 192K -f mp3 sound.mp3
    
    staffs = []
    img = os.listdir("/content/pytorch-AdaIN/stylized_frames")
    img.sort()
    
    for i in img:
        staffs.append("/content/pytorch-AdaIN/stylized_frames/" + i)
    
    staff = cv2.imread(staffs[0])  # get size from the 1st frame
    writer = cv2.VideoWriter(
        'stylized_video.mp4',
        cv2.VideoWriter_fourcc(*'MP4V'),  # codec
        fps_of_video,
        (staff.shape[1], staff.shape[0]),
        isColor=len(staff.shape) > 2
    )
    
    for staff in map(cv2.imread, staffs):
        writer.write(staff)
    
    writer.release()
    
    dstvid = 'stylized_video.mp4'
    tmpfile = dstvid.replace('.mp4', '-audio.mp4')
    !ffmpeg -i sound.mp3 -i $dstvid $tmpfile
    !mv -f $tmpfile $dstvid

# Function to download the final video
def download_final_video():
    files.download('/content/pytorch-AdaIN/stylized_video.mp4')

# Main code execution
vid, fps_of_video, frames_of_video = upload_video()
split_video_into_frames(vid)
pic_name = upload_style_image()
style_transfer(fram_path, pic_name)
join_frames_into_video(fps_of_video)
download_final_video()
